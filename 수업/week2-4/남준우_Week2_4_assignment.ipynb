{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592U6lXs3d2t"
      },
      "source": [
        "# Week2_4 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- 커스텀 모듈(`helper.py`)에서 **클래스와 함수를 임포트**할 수 있다.\n",
        "- **autograd**의 개념 복습\n",
        "\n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- train() 함수에 **epoch, scheduler, grad_clipping**을 추가할 수 있다.\n",
        "- **validate() 함수를 구현**할 수 있다.\n",
        "\n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- train() 함수를 사용해 데이터를 **4 epoch 학습**할 수 있다. \n",
        "- **predict 함수를 구현**할 수 있다. \n",
        "- **evaluation metric 구현**할 수 있다. \n",
        "    - accuracy\n",
        "\n",
        "\n",
        "\n",
        "### Reference\n",
        "- [Pytorch Autograd Explain official document](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.370876Z",
          "start_time": "2022-02-02T04:01:46.520392Z"
        },
        "id": "KSX-wQA1RD1h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.375658Z",
          "start_time": "2022-02-02T04:01:47.372242Z"
        },
        "id": "MH7RJjtZXOHf"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "seed = 7777\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:07:00.849353Z",
          "start_time": "2022-01-31T13:06:56.187962Z"
        },
        "id": "62plMahMWr0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf356ba-d840-40cd-bd7b-df2ec957817c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WagJcj-Ud4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b132049-07b3-4e4f-a5d2-ea1b9dba9617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnETqIqdVApF"
      },
      "outputs": [],
      "source": [
        "# 어제 자신이 구현한 helper.py 모듈 경로를 입력\n",
        "sys.path.append('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.735578Z",
          "start_time": "2022-02-02T04:01:49.475969Z"
        },
        "id": "N84mZeYMUFxJ"
      },
      "outputs": [],
      "source": [
        "# helper 모듈을 import하면 이전에 구현했던 다양한 함수 및 클래스를 사용할 수 있음 \n",
        "# 함수: set_device()\n",
        "# 함수: custom_collate_fn() \n",
        "# 클래스: CustomDataset\n",
        "# 클래스: CustomClassifier\n",
        "# 가 import 됨\n",
        "\n",
        "from help import *\n",
        "from torch.utils.data import RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.771743Z",
          "start_time": "2022-02-02T04:01:49.736866Z"
        },
        "id": "oR5EWmh5UFxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241d4196-faa3-40de-8cbb-ab822c1a510d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# device\n",
        "device = set_device()\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkNxrCV45Q3m"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YBUQykS5Q3n"
      },
      "source": [
        "### 모듈에서 클래스와 함수를 임포트해 다음을 구현\n",
        "- train_dataset, train_dataloader\n",
        "- valid_dataset, valid_dataloader\n",
        "- test_dataset, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv"
      ],
      "metadata": {
        "id": "cjNksUEwGACb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b16b9a-7d53-432e-9692-24fdc6a02e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-03 08:41:40--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 971625 (949K) [text/plain]\n",
            "Saving to: ‘sample_df.csv’\n",
            "\n",
            "sample_df.csv       100%[===================>] 948.85K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-03-03 08:41:40 (20.7 MB/s) - ‘sample_df.csv’ saved [971625/971625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv"
      ],
      "metadata": {
        "id": "kXfk8ZEHGB0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a4042b-d1f2-485b-e916-54e64745fa78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-03 08:41:40--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101383 (99K) [text/plain]\n",
            "Saving to: ‘sample_df_test.csv’\n",
            "\n",
            "\rsample_df_test.csv    0%[                    ]       0  --.-KB/s               \rsample_df_test.csv  100%[===================>]  99.01K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-03-03 08:41:40 (7.12 MB/s) - ‘sample_df_test.csv’ saved [101383/101383]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.037044Z",
          "start_time": "2022-02-02T04:01:52.707669Z"
        },
        "id": "KVo5dPnmUFxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7139e6-b348-4417-e3e4-531617eb5692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape : (10000, 3)\n",
            "test shape : (1000, 3)\n"
          ]
        }
      ],
      "source": [
        "# 학습 & 평가 데이터셋 로드\n",
        "# 학습 및 평가 샘플 데이터 개수는 각각 10,000개, 1,000개\n",
        "\n",
        "df_train = pd.read_csv('sample_df.csv')\n",
        "df_test = pd.read_csv('sample_df_test.csv')\n",
        "\n",
        "print(f\"train shape : {df_train.shape}\")\n",
        "print(f\"test shape : {df_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.085720Z",
          "start_time": "2022-02-02T04:01:53.081413Z"
        },
        "id": "Ql82Ew2VUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79995850-24c6-4a90-9ff3-e451737d5518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10000\n",
            "Train Dataset 1st element: ('나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.', 0)\n",
            "Test Dataset len: 1000\n",
            "Test Dataset 1st element: ('신용문객잔 보고 후속편인줄 알고 봤더만 완전 개판이네 18.. 이련결 그냥 절에나 쳐 들어 가라.. 회오리에서 싸우는 신 참 가관이더라 .. 서극도 완전 쓰레기 감독이 다 됐구나.. 액션도 쓰레기고 배우들 연기도 참 가관이더라 18', 0)\n"
          ]
        }
      ],
      "source": [
        "# Dataset 구현\n",
        "# helper.py에 있는 CustomDataset 활용하여 train datset, test dataset 만들기\n",
        "\n",
        "train_dataset = CustomDataset(df_train[\"document\"], df_train[\"label\"])\n",
        "test_dataset = CustomDataset(df_test[\"document\"], df_test[\"label\"])\n",
        "\n",
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Train Dataset 1st element: {train_dataset[0]}\")\n",
        "\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")\n",
        "print(f\"Test Dataset 1st element: {test_dataset[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.152070Z",
          "start_time": "2022-02-02T04:01:53.145410Z"
        },
        "id": "7WUY6h8WUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944e3f28-1fc3-44f1-df95-4334b6231a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset len: 9000\n",
            "Valid dataset len: 1000\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# Train Dataset을 학습과 검증 셋으로 분리\n",
        "# 학습 셋과 검증 셋의 비율은 9:1\n",
        "# torch.utils.data에서 제공되는 데이터 세트를 임의로 분할할 수 있는 함수 찾아서 사용\n",
        "n_train_sample = df_train.shape[0]\n",
        "\n",
        "n_train = int(n_train_sample * 0.9)\n",
        "n_valid = n_train_sample - n_train \n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid])\n",
        "\n",
        "print(f\"Train dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid dataset len: {len(valid_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.268838Z",
          "start_time": "2022-02-02T04:01:53.263780Z"
        },
        "id": "H5nc7SpTUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0f1eb9-ee6a-40c2-a6f5-05612eeb95de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 282\n",
            "Valid dataloader # steps: 16\n",
            "Test dataloader # steps: 16\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# DataLoader 구현\n",
        "# train과 validation의 batch size는 각각 32, 64로 설정\n",
        "# test의 batch size는 validation과 동일\n",
        "# train에 사용할 DataLoader에서는 sampler로 RandomSampler 사용\n",
        "# validation과 test에 사용할 DataLoader에서는 sampler로 SequentialSampler 사용\n",
        "# 모든 DataLoader의 collate_fn은 helper.py에 있는 custom_collate_fn 사용\n",
        "\n",
        "train_batch_size = 32\n",
        "valid_batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = train_batch_size, collate_fn = custom_collate_fn, sampler = RandomSampler(train_dataset))\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = valid_batch_size, collate_fn = custom_collate_fn, sampler = SequentialSampler(valid_dataset))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = valid_batch_size, collate_fn = custom_collate_fn, sampler = SequentialSampler(test_dataset))\n",
        "\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kEgqvBIUFxN"
      },
      "source": [
        "### `auto_grad` 개념 복습\n",
        "- torch의 `auto_grad` 기능\n",
        "    - pytorch는 `requires_grad` 파리미터의 값이 True인 텐서에 한해서 미분값을 자동으로 계산한다.\n",
        "    - 미분값은 `loss.backward()` 가 호출될 때 자동으로 계산된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:23.502936Z",
          "start_time": "2022-01-31T13:45:20.029987Z"
        },
        "id": "oYjYpQ1DUFxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2b07fb6415e84849bf570a11b1b6d3f1",
            "da2e45428ba84722991b9910f9b597b0",
            "152204bd289443fd88447a0906f57a4e",
            "82a3add6add54f4786036d87e7dd85ef",
            "23d72b3a64bf4972b1ce47e938748cee",
            "20489222b2bc455cbee084d8b89383ef",
            "9795f755ed2847a1aa4350663f3eb908",
            "5d44fe95a1344fea92759846e9f774e3",
            "dc85027c2f4a43df8533daa1f25e73db",
            "b254d435d9594f10a2fd38b9eb4f4683",
            "f252004bf2164a269e4d8afb9b30956f",
            "3cf9d40054c14ebf994a24721051bee0",
            "1dd96de151c54e0eae831192e0a65ecb",
            "d3570eedc7b5435396b02d7fb84617e9",
            "0df9ee36631049e38c93a3e8833ed0ea",
            "bf86aa679c65463692ffb334ef676dcf",
            "7c5d47549034464f952085b016bc2dcf",
            "d6b1d16aa2e4432d89f023c1fed7e9f8",
            "9e41c449543f41d0bf9161385dcf4480",
            "4938f26223144046b9950d79eea583c8",
            "ce0c00d1199842e6beb1e1c3130c9c01",
            "4a321916f2ef49b1b7ac9f4030c2dc03"
          ]
        },
        "outputId": "a83c50f5-a821-4909-a7df-ff7914a0faf5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b07fb6415e84849bf570a11b1b6d3f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cf9d40054c14ebf994a24721051bee0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# helper.py에 있는 CustomClassifier 모델을 로드해 model_freeze 변수에 instance를 생성\n",
        "\n",
        "# hidden_size=768\n",
        "# n_label=2\n",
        "# freeze_base=True\n",
        "\n",
        "model_freeze = CustomClassifier(hidden_size=768, n_label=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:34.604914Z",
          "start_time": "2022-01-31T13:45:34.586711Z"
        },
        "id": "XxNFh8KZUFxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db0d042-1346-4586-b2f8-6f5fae377b10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=32, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# model_freeze 모델의 모든 파라미터를 출력해보고 아래 질문에 답해 보자\n",
        "\n",
        "model_freeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KloNNAKI5Q3r"
      },
      "source": [
        "### `auto_grad` 개념 및 모델 구조 복습을 위해 다음 항목에 답해 보자\n",
        "- `bert.encoder.layer.0.attention.self.query.weight` 텐서의 gradient는 True인 상태인가?\n",
        "> 네\n",
        "- `classifier.0.weight` 텐서의 shape은? \n",
        "> torch.Size([32, 768])\n",
        "- `classifier.0.weight` 텐서는 freeze 상태인가 ? \n",
        "> 아니요\n",
        "\n",
        "- `classifier.0.weight` 텐서의 gradient 값은 무엇인가? \n",
        "> None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iIrHg1xUFxP"
      },
      "source": [
        "### 위 모델 (`model_freeze`)의 모든 파라미터의 gradient를 freeze 해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:49:26.820569Z",
          "start_time": "2022-01-31T13:49:26.816511Z"
        },
        "id": "sHkaFgC8UFxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e695455-7a96-4ea6-f874-35005d477b29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=32, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# 모든 파라미터의 gradient를 freeze 해보고 제대로 변경되었는지 \b확인하기 위해 모델의 모든 파라미터를 출력해보자.\n",
        "for param in model_freeze.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model_freeze"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freeze.classifier[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TJa5nqoZFLR",
        "outputId": "b4b95ff6-65da-44fa-8e8e-fa377b479b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0175, -0.0060, -0.0251,  ...,  0.0293, -0.0258, -0.0341],\n",
              "        [ 0.0007, -0.0295, -0.0096,  ..., -0.0269,  0.0298,  0.0083],\n",
              "        [ 0.0201,  0.0189, -0.0330,  ..., -0.0082,  0.0135,  0.0053],\n",
              "        ...,\n",
              "        [ 0.0178,  0.0220,  0.0258,  ...,  0.0003,  0.0011,  0.0074],\n",
              "        [ 0.0020, -0.0170, -0.0345,  ..., -0.0314, -0.0292, -0.0003],\n",
              "        [-0.0113, -0.0169, -0.0195,  ..., -0.0068,  0.0018,  0.0051]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsMgM3sK5Q3t"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUn-6PFP5Q3t"
      },
      "source": [
        "### `scheduler` 를 생성 \n",
        "- 스케쥴러를 알기 전에 먼저 `epoch`의 개념을 알아야 한다. Epoch는 dataset를 **몇 번 반복**해 학습할 것인지를 의미한다. 만약 dataset의 개수가 2,000개이고 epoch을 2번 학습하게 되면 총 4,000개의 데이터를 학습하게 된다.   \n",
        "- 스케쥴러는 epoch에 따라 learning rate의 값을 조정하는 것을 의미한다. \n",
        "- 예를 들어 [여기](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup)의 그림에서 볼 수 있듯이 `get_linear_schedule_with_warmup`는 특정 step까지는 learning rate를 천천히 상승시키다가 고점에 도달하면 다시 하락시킨다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FuADvuT5Q3t"
      },
      "source": [
        "### `model`, `optimizer`, `scheduler`를 초기화(=인스턴스 생성)하는 함수를 구현하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.217735Z",
          "start_time": "2022-02-02T04:01:59.210482Z"
        },
        "id": "-sE7xjYcRD1p"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.549660Z",
          "start_time": "2022-02-02T04:01:59.545752Z"
        },
        "id": "2eTFXzy8VK9R"
      },
      "outputs": [],
      "source": [
        "# model:CustomClassifier 사용, hidden size는 768, label 개수는 2\n",
        "# optimizer: AdamW 사용, learning rate는 2e-5\n",
        "# scheduler: transformers.get_linear_schedule_with_warmup 함수 사용, 단, num_warmup_steps 매개 변수는 사용하지 않음\n",
        "\n",
        "def initializer(train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러를 초기화한 후 반환\n",
        "    \"\"\"\n",
        "    \n",
        "    model = CustomClassifier(hidden_size=768, n_label=2)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, 0, total_steps)\n",
        "\n",
        "    return model, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz-8_5as5Q3u"
      },
      "source": [
        "### model, optimizer, scheduler의 파라미터 저장하는 함수를 구현하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:02.786877Z",
          "start_time": "2022-02-02T04:02:02.783726Z"
        },
        "id": "vIP1BjFA5Q3u"
      },
      "outputs": [],
      "source": [
        "# 모델 저장 함수 구현\n",
        "\n",
        "def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n",
        "    file_name = f'{path}/model.ckpt.{epoch}'\n",
        "    print(file_name)\n",
        "    # torch.save 함수 참고\n",
        "    torch.save(\n",
        "        {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss' : loss\n",
        "        }, \n",
        "        file_name\n",
        "    )\n",
        "    \n",
        "    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3BUrgtJ5Q3v"
      },
      "source": [
        "### `validate()` 함수 구현 \n",
        "- `validate()` 함수 내 model의 상태는 **evaluate**이어야 한다. evaluate 상태의 model은 dropout을 진행하지 않는다. \n",
        "- **forward**를 진행할 때 `with torch.no_grad(): ...` 설정해 미분 계산을 방지한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:11.636684Z",
          "start_time": "2022-02-02T04:02:11.631550Z"
        },
        "id": "VHpuV0CXUFxR"
      },
      "outputs": [],
      "source": [
        "# input: model, valid_dataloader\n",
        "# output: loss, 정확도\n",
        "\n",
        "def validate(model, valid_dataloader):\n",
        "    global loss_fct\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch =  tuple(item.to(device) for item in batch)\n",
        "        batch_input, batch_label = batch\n",
        "        # gradient 계산하지 않고 forward 진행\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc += acc\n",
        "\n",
        "    total_loss = total_loss/(step + 1)\n",
        "    total_acc = total_acc/(step + 1)*100\n",
        "\n",
        "    return total_loss, total_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NukaJc15UFxQ"
      },
      "source": [
        "### `train()` 함수에 `epoch`와 `clip_grad_norm` 추가\n",
        "- data_loader를 `epoch`만큼 반복하면서 학습하도록 `train()` 함수를 수정하라\n",
        "- `gradient cliping`은 미분 값 너무 큰 경우 gradient exploding되는 현상을 막기 위해 미분값이 `threshold`를 넘을 경우 특정 비율을 미분 값에 곱해 크기를 줄여준다.\n",
        "- Reference\n",
        "  - [clip_grad_norm_ official document](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "  - [그래디언트 클립핑 설명 한국어 블로그](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-6/05-gradient-clipping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:10.624280Z",
          "start_time": "2022-02-02T04:02:10.615781Z"
        },
        "id": "ZvY5rxDKHQAp"
      },
      "outputs": [],
      "source": [
        "# 위에서 구현한 모델 저장 함수(save_checkpoint)와 validate 함수도 추가해보자\n",
        "\n",
        "loss_fct = CrossEntropyLoss()\n",
        "\n",
        "def train(model, train_dataloader, valid_dataloader=None, epochs=2):\n",
        "        global scheduler, loss_fct\n",
        "        \n",
        "        # train_dataloaer 학습을 epochs만큼 반복\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            \n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "        \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "                batch_input, batch_label = batch\n",
        "            \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "                model.zero_grad()\n",
        "            \n",
        "                # forward\n",
        "                logits = model(**batch_input)\n",
        "            \n",
        "                # loss\n",
        "                loss = loss_fct(logits, batch_label)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 (max_norm = 1)\n",
        "                clip_grad_norm_(model.parameters(), max_norm  = 1)      \n",
        "\n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                \n",
        "                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 10 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # reset \n",
        "                    batch_loss, batch_count = 0,0\n",
        "\n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "            \n",
        "            # checkpoint 저장\n",
        "            save_checkpoint(\"/content\", model, optimizer, scheduler, epoch, loss)\n",
        "                \n",
        "        print(\"Train Completed. End Program.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NWKzxIaf1QJ"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFWnii7a5Q3w"
      },
      "source": [
        "### 학습 데이터를 epoch 4까지 학습\n",
        "- 매 epoch마다 다음을 수행한다.\n",
        "  - 학습이 끝난 후 validate() 함수 실행 \n",
        "  - validate() 함수가 끝난 후 model save 함수 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:02:11.377612Z",
          "start_time": "2022-02-02T04:02:20.931961Z"
        },
        "id": "7Er1qKtsf1QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cb0562-9338-487a-a115-d71041e34a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 4 epochs: 1128\n",
            "*****Epoch 0 Train Start*****\n",
            "Epoch: 0, Step : 10, LR : 1.9804964539007094e-05, Avg Loss : 0.6653\n",
            "Epoch: 0, Step : 20, LR : 1.962765957446809e-05, Avg Loss : 0.5984\n",
            "Epoch: 0, Step : 30, LR : 1.945035460992908e-05, Avg Loss : 0.5340\n",
            "Epoch: 0, Step : 40, LR : 1.927304964539007e-05, Avg Loss : 0.4404\n",
            "Epoch: 0, Step : 50, LR : 1.9095744680851064e-05, Avg Loss : 0.3848\n",
            "Epoch: 0, Step : 60, LR : 1.891843971631206e-05, Avg Loss : 0.4348\n",
            "Epoch: 0, Step : 70, LR : 1.8741134751773053e-05, Avg Loss : 0.4515\n",
            "Epoch: 0, Step : 80, LR : 1.8563829787234043e-05, Avg Loss : 0.3575\n",
            "Epoch: 0, Step : 90, LR : 1.8386524822695038e-05, Avg Loss : 0.4216\n",
            "Epoch: 0, Step : 100, LR : 1.8209219858156032e-05, Avg Loss : 0.3604\n",
            "Epoch: 0, Step : 110, LR : 1.8031914893617023e-05, Avg Loss : 0.3407\n",
            "Epoch: 0, Step : 120, LR : 1.7854609929078013e-05, Avg Loss : 0.3797\n",
            "Epoch: 0, Step : 130, LR : 1.7677304964539008e-05, Avg Loss : 0.3819\n",
            "Epoch: 0, Step : 140, LR : 1.7500000000000002e-05, Avg Loss : 0.4155\n",
            "Epoch: 0, Step : 150, LR : 1.7322695035460996e-05, Avg Loss : 0.3795\n",
            "Epoch: 0, Step : 160, LR : 1.7145390070921987e-05, Avg Loss : 0.4421\n",
            "Epoch: 0, Step : 170, LR : 1.696808510638298e-05, Avg Loss : 0.4227\n",
            "Epoch: 0, Step : 180, LR : 1.6790780141843972e-05, Avg Loss : 0.3500\n",
            "Epoch: 0, Step : 190, LR : 1.6613475177304966e-05, Avg Loss : 0.3002\n",
            "Epoch: 0, Step : 200, LR : 1.6436170212765957e-05, Avg Loss : 0.3421\n",
            "Epoch: 0, Step : 210, LR : 1.625886524822695e-05, Avg Loss : 0.3810\n",
            "Epoch: 0, Step : 220, LR : 1.6081560283687945e-05, Avg Loss : 0.3025\n",
            "Epoch: 0, Step : 230, LR : 1.590425531914894e-05, Avg Loss : 0.3482\n",
            "Epoch: 0, Step : 240, LR : 1.572695035460993e-05, Avg Loss : 0.3411\n",
            "Epoch: 0, Step : 250, LR : 1.5549645390070924e-05, Avg Loss : 0.2781\n",
            "Epoch: 0, Step : 260, LR : 1.5372340425531915e-05, Avg Loss : 0.3479\n",
            "Epoch: 0, Step : 270, LR : 1.5195035460992908e-05, Avg Loss : 0.3676\n",
            "Epoch: 0, Step : 280, LR : 1.5017730496453902e-05, Avg Loss : 0.2982\n",
            "Epoch 0 Total Mean Loss : 0.3954\n",
            "*****Epoch 0 Train Finish*****\n",
            "\n",
            "*****Epoch 0 Valid Start*****\n",
            "Epoch 0 Valid Loss : 0.3661 Valid Acc : 84.18\n",
            "*****Epoch 0 Valid Finish*****\n",
            "\n",
            "/content/model.ckpt.0\n",
            "Saving epoch 0 checkpoint at /content/model.ckpt.0\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 10, LR : 1.4804964539007095e-05, Avg Loss : 0.2556\n",
            "Epoch: 1, Step : 20, LR : 1.4627659574468087e-05, Avg Loss : 0.2073\n",
            "Epoch: 1, Step : 30, LR : 1.4450354609929078e-05, Avg Loss : 0.3005\n",
            "Epoch: 1, Step : 40, LR : 1.427304964539007e-05, Avg Loss : 0.2403\n",
            "Epoch: 1, Step : 50, LR : 1.4095744680851065e-05, Avg Loss : 0.2772\n",
            "Epoch: 1, Step : 60, LR : 1.3918439716312057e-05, Avg Loss : 0.2533\n",
            "Epoch: 1, Step : 70, LR : 1.3741134751773051e-05, Avg Loss : 0.2283\n",
            "Epoch: 1, Step : 80, LR : 1.3563829787234044e-05, Avg Loss : 0.1842\n",
            "Epoch: 1, Step : 90, LR : 1.3386524822695038e-05, Avg Loss : 0.2896\n",
            "Epoch: 1, Step : 100, LR : 1.320921985815603e-05, Avg Loss : 0.2358\n",
            "Epoch: 1, Step : 110, LR : 1.3031914893617021e-05, Avg Loss : 0.2818\n",
            "Epoch: 1, Step : 120, LR : 1.2854609929078014e-05, Avg Loss : 0.2496\n",
            "Epoch: 1, Step : 130, LR : 1.2677304964539008e-05, Avg Loss : 0.2595\n",
            "Epoch: 1, Step : 140, LR : 1.25e-05, Avg Loss : 0.2605\n",
            "Epoch: 1, Step : 150, LR : 1.2322695035460995e-05, Avg Loss : 0.2286\n",
            "Epoch: 1, Step : 160, LR : 1.2145390070921987e-05, Avg Loss : 0.2274\n",
            "Epoch: 1, Step : 170, LR : 1.196808510638298e-05, Avg Loss : 0.2838\n",
            "Epoch: 1, Step : 180, LR : 1.1790780141843972e-05, Avg Loss : 0.2612\n",
            "Epoch: 1, Step : 190, LR : 1.1613475177304965e-05, Avg Loss : 0.2379\n",
            "Epoch: 1, Step : 200, LR : 1.1436170212765957e-05, Avg Loss : 0.1809\n",
            "Epoch: 1, Step : 210, LR : 1.1258865248226952e-05, Avg Loss : 0.2069\n",
            "Epoch: 1, Step : 220, LR : 1.1081560283687944e-05, Avg Loss : 0.2349\n",
            "Epoch: 1, Step : 230, LR : 1.0904255319148938e-05, Avg Loss : 0.2153\n",
            "Epoch: 1, Step : 240, LR : 1.072695035460993e-05, Avg Loss : 0.2453\n",
            "Epoch: 1, Step : 250, LR : 1.0549645390070923e-05, Avg Loss : 0.2664\n",
            "Epoch: 1, Step : 260, LR : 1.0372340425531916e-05, Avg Loss : 0.2268\n",
            "Epoch: 1, Step : 270, LR : 1.0195035460992908e-05, Avg Loss : 0.2136\n",
            "Epoch: 1, Step : 280, LR : 1.00177304964539e-05, Avg Loss : 0.2377\n",
            "Epoch 1 Total Mean Loss : 0.2418\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 0.3553 Valid Acc : 86.00\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "/content/model.ckpt.1\n",
            "Saving epoch 1 checkpoint at /content/model.ckpt.1\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 9.804964539007093e-06, Avg Loss : 0.1638\n",
            "Epoch: 2, Step : 20, LR : 9.627659574468086e-06, Avg Loss : 0.1165\n",
            "Epoch: 2, Step : 30, LR : 9.450354609929078e-06, Avg Loss : 0.1853\n",
            "Epoch: 2, Step : 40, LR : 9.273049645390073e-06, Avg Loss : 0.1355\n",
            "Epoch: 2, Step : 50, LR : 9.095744680851063e-06, Avg Loss : 0.1329\n",
            "Epoch: 2, Step : 60, LR : 8.918439716312058e-06, Avg Loss : 0.1660\n",
            "Epoch: 2, Step : 70, LR : 8.74113475177305e-06, Avg Loss : 0.1345\n",
            "Epoch: 2, Step : 80, LR : 8.563829787234044e-06, Avg Loss : 0.1588\n",
            "Epoch: 2, Step : 90, LR : 8.386524822695035e-06, Avg Loss : 0.1571\n",
            "Epoch: 2, Step : 100, LR : 8.20921985815603e-06, Avg Loss : 0.1562\n",
            "Epoch: 2, Step : 110, LR : 8.031914893617022e-06, Avg Loss : 0.1587\n",
            "Epoch: 2, Step : 120, LR : 7.854609929078016e-06, Avg Loss : 0.1517\n",
            "Epoch: 2, Step : 130, LR : 7.677304964539007e-06, Avg Loss : 0.1191\n",
            "Epoch: 2, Step : 140, LR : 7.500000000000001e-06, Avg Loss : 0.1588\n",
            "Epoch: 2, Step : 150, LR : 7.3226950354609935e-06, Avg Loss : 0.1591\n",
            "Epoch: 2, Step : 160, LR : 7.145390070921986e-06, Avg Loss : 0.1613\n",
            "Epoch: 2, Step : 170, LR : 6.968085106382979e-06, Avg Loss : 0.1859\n",
            "Epoch: 2, Step : 180, LR : 6.790780141843972e-06, Avg Loss : 0.1371\n",
            "Epoch: 2, Step : 190, LR : 6.613475177304965e-06, Avg Loss : 0.1588\n",
            "Epoch: 2, Step : 200, LR : 6.436170212765958e-06, Avg Loss : 0.1375\n",
            "Epoch: 2, Step : 210, LR : 6.258865248226951e-06, Avg Loss : 0.1277\n",
            "Epoch: 2, Step : 220, LR : 6.081560283687944e-06, Avg Loss : 0.1955\n",
            "Epoch: 2, Step : 230, LR : 5.904255319148937e-06, Avg Loss : 0.1479\n",
            "Epoch: 2, Step : 240, LR : 5.7269503546099295e-06, Avg Loss : 0.1838\n",
            "Epoch: 2, Step : 250, LR : 5.549645390070923e-06, Avg Loss : 0.2153\n",
            "Epoch: 2, Step : 260, LR : 5.372340425531915e-06, Avg Loss : 0.1322\n",
            "Epoch: 2, Step : 270, LR : 5.195035460992908e-06, Avg Loss : 0.1743\n",
            "Epoch: 2, Step : 280, LR : 5.017730496453901e-06, Avg Loss : 0.1533\n",
            "Epoch 2 Total Mean Loss : 0.1584\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 0.4115 Valid Acc : 86.15\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "/content/model.ckpt.2\n",
            "Saving epoch 2 checkpoint at /content/model.ckpt.2\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 4.804964539007093e-06, Avg Loss : 0.1111\n",
            "Epoch: 3, Step : 20, LR : 4.6276595744680855e-06, Avg Loss : 0.0888\n",
            "Epoch: 3, Step : 30, LR : 4.450354609929078e-06, Avg Loss : 0.1327\n",
            "Epoch: 3, Step : 40, LR : 4.273049645390071e-06, Avg Loss : 0.0925\n",
            "Epoch: 3, Step : 50, LR : 4.095744680851064e-06, Avg Loss : 0.1362\n",
            "Epoch: 3, Step : 60, LR : 3.918439716312057e-06, Avg Loss : 0.0942\n",
            "Epoch: 3, Step : 70, LR : 3.74113475177305e-06, Avg Loss : 0.1137\n",
            "Epoch: 3, Step : 80, LR : 3.5638297872340426e-06, Avg Loss : 0.1444\n",
            "Epoch: 3, Step : 90, LR : 3.386524822695036e-06, Avg Loss : 0.0751\n",
            "Epoch: 3, Step : 100, LR : 3.2092198581560285e-06, Avg Loss : 0.1298\n",
            "Epoch: 3, Step : 110, LR : 3.031914893617022e-06, Avg Loss : 0.0958\n",
            "Epoch: 3, Step : 120, LR : 2.8546099290780144e-06, Avg Loss : 0.0861\n",
            "Epoch: 3, Step : 130, LR : 2.6773049645390077e-06, Avg Loss : 0.1486\n",
            "Epoch: 3, Step : 140, LR : 2.5e-06, Avg Loss : 0.1037\n",
            "Epoch: 3, Step : 150, LR : 2.322695035460993e-06, Avg Loss : 0.0998\n",
            "Epoch: 3, Step : 160, LR : 2.145390070921986e-06, Avg Loss : 0.1355\n",
            "Epoch: 3, Step : 170, LR : 1.968085106382979e-06, Avg Loss : 0.0977\n",
            "Epoch: 3, Step : 180, LR : 1.790780141843972e-06, Avg Loss : 0.1053\n",
            "Epoch: 3, Step : 190, LR : 1.6134751773049648e-06, Avg Loss : 0.1536\n",
            "Epoch: 3, Step : 200, LR : 1.4361702127659578e-06, Avg Loss : 0.1362\n",
            "Epoch: 3, Step : 210, LR : 1.2588652482269503e-06, Avg Loss : 0.0854\n",
            "Epoch: 3, Step : 220, LR : 1.0815602836879434e-06, Avg Loss : 0.1386\n",
            "Epoch: 3, Step : 230, LR : 9.042553191489363e-07, Avg Loss : 0.1202\n",
            "Epoch: 3, Step : 240, LR : 7.26950354609929e-07, Avg Loss : 0.0547\n",
            "Epoch: 3, Step : 250, LR : 5.496453900709221e-07, Avg Loss : 0.0498\n",
            "Epoch: 3, Step : 260, LR : 3.723404255319149e-07, Avg Loss : 0.1086\n",
            "Epoch: 3, Step : 270, LR : 1.9503546099290782e-07, Avg Loss : 0.0865\n",
            "Epoch: 3, Step : 280, LR : 1.773049645390071e-08, Avg Loss : 0.0650\n",
            "Epoch 3 Total Mean Loss : 0.1065\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 0.4709 Valid Acc : 85.70\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "/content/model.ckpt.3\n",
            "Saving epoch 3 checkpoint at /content/model.ckpt.3\n",
            "Train Completed. End Program.\n"
          ]
        }
      ],
      "source": [
        "# 4 epoch 학습\n",
        "epochs=4\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)\n",
        "train(model, train_dataloader, valid_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T03:27:18.246441Z",
          "start_time": "2022-02-02T03:27:18.236617Z"
        },
        "id": "vA3_vqqCXccc"
      },
      "source": [
        "### 가장 dev acc 성능이 높았던 epoch의 모델의 체크 포인트를 불러와 로드하자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:27.646150Z",
          "start_time": "2022-02-02T06:22:26.945572Z"
        },
        "id": "mvfkSff25Q3z"
      },
      "outputs": [],
      "source": [
        "# torch.load 함수 사용\n",
        "\n",
        "checkpoint = torch.load('/content/drive/MyDrive/wanted_pre_onboarding/model.ckpt.3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:36.415665Z",
          "start_time": "2022-02-02T06:22:36.407250Z"
        },
        "id": "YqcxMmTj5Q3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f340909a-cb64-4c28-a437-63be104bc9a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# checkpoint의 key 종류를 확인\n",
        "checkpoint.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.272939Z",
          "start_time": "2022-02-02T06:22:37.010491Z"
        },
        "id": "wTvFYgNi5Q30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa978bb9-659e-4480-c140-d24a4d56b5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# 위에서 구현한 initializer 함수 사용하여 model, optimizer, scheduler 초기화\n",
        "\n",
        "epochs = 1\n",
        "model = CustomClassifier(hidden_size=768, n_label=2)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, 0, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.443912Z",
          "start_time": "2022-02-02T06:22:40.274323Z"
        },
        "id": "CtR2sTW55Q30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7992ff7-7000-4bdf-c638-e7ca62a61f40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzske7SR5Q30"
      },
      "source": [
        "### 모델 예측 함수 구현\n",
        "- test_dataloader를 입력받아 모델이 예측한 확률값 (probs)과 실제 정답 (label) 을 출력하는 `\bpredict()` 함수를 구현하자.\n",
        "- 함수 정의\n",
        "  - 입력 매개변수\n",
        "    - `model` : `CustomClassifier` 모델. logits를 반환함 \n",
        "    - `test_dataloader` : test 데이터셋의 텍스트와 레이블을 배치로 갖는 dataloader\n",
        "  - 조건\n",
        "    - `test_dataloader`는 이터레이터기 때문에 이터레이터를 순회하면서 `all_logits` 리스트에 배치 단위의 logits를 저장하고 `all_labels` 리스트에 배치 단위의 레이블 (0 또는 1 값)을 저장하라\n",
        "  - 반환값\n",
        "    - `probs`\n",
        "      - logits에 softmax 함수를 취한 확률값. (test data 개수, label 개수) shape을 가짐. \bnp.array 타입으로 데이터 타입을 변환할 것.\n",
        "    - `labels`\n",
        "      - 0 또는 1 값을 갖는 np.array. (test data 개수,) shape을 가짐."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:48.062229Z",
          "start_time": "2022-02-02T06:22:48.057531Z"
        },
        "id": "yQ7WiD1Oigg9"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    # model을 eval 모드로 설정 & device 할당\n",
        "    model.eval() \n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "        # batch_input을 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "        batch_input, batch_label = batch\n",
        "\n",
        "        # model에 batch_input을 넣어 logit 반환 & all_logits, all_labels 리스트에 값 추가 \n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "        \n",
        "        all_logits.append(F.softmax(logits, dim=1))\n",
        "        all_labels.append(batch_label)\n",
        "\n",
        "    probs = [x.cpu().numpy() for x in all_logits] # logits을 확률값으로 변환 & Tensor 타입을 numpy.array 타입으로 변환\n",
        "    all_labels = [x.cpu().numpy() for x in all_labels] #  Tensor 타입을 numpy.array 타입으로 변환\n",
        "\n",
        "    return probs, all_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델이 예측한 확률값과 실제 label을 입력 받아 정확도를 출력하는 **accuracy()** 함수를 구현하자. \n",
        "- 함수 정의 \n",
        "  - 입력 매개변수 \n",
        "    - `probs` : `predict()` 함수의 반환값. 2차원의 np.array\n",
        "    - `labels` : `predict()` 함수의 반환값. 1차원의 np.array\n",
        "  - 조건\n",
        "    - `probs`의 확률값이 0.5 이상이면 1, 이하이면 0이 되도록 만든다. 모델이 예측한 레이블을 실제값(`labels`)과 비교해 예측값과 실제값이 같으면 1, 다르면 0 점수를 준다. 모든 데이터에 대해 점수의 평균값이 accuracy 값이다. \n",
        "  - 반환값 \n",
        "    - `acc` : 정확도 (Float type)"
      ],
      "metadata": {
        "id": "lOxCjZ2g6ZeK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:48.296419Z",
          "start_time": "2022-02-02T06:22:48.293737Z"
        },
        "id": "42-umZ3m5Q32"
      },
      "outputs": [],
      "source": [
        "# accuracy 함수 구현\n",
        "def accuracy(probs, labels):\n",
        "    y_pred =  []\n",
        "    total_acc = 0\n",
        "\n",
        "    for i in probs:\n",
        "      y_pred.append(np.array([0 if x[0] >= 0.5 else 1 for x in i])) # probs(확률값)을 label로 변경(0.5 이상이면 1, 0.5 미만이면 0)\n",
        "    \n",
        "    for i in range(len(y_pred)):\n",
        "        acc = (y_pred[i] == labels[i]).mean()\n",
        "        total_acc += acc\n",
        "\n",
        "    total_acc = total_acc / (i + 1) * 100\n",
        "    return total_acc "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.752497Z",
          "start_time": "2022-02-02T06:22:48.652784Z"
        },
        "id": "SwkrRPAhjsXb"
      },
      "outputs": [],
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.759367Z",
          "start_time": "2022-02-02T06:24:22.753997Z"
        },
        "id": "MxDI8PRA5Q32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ca2690-9b60-4fe0-d253-6bcc791c8fe8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.640625"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "accuracy(probs, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mqUfkx-5Q33"
      },
      "source": [
        "### `sklearn.metrics`의 `accuracy_score`, `roc_auc_score` 함수를 이용해 정확도와 auc를 계산하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.111879Z",
          "start_time": "2022-02-02T06:24:22.760568Z"
        },
        "id": "VFWj4lcp5Q33"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "for i in probs:\n",
        "  y_pred.append(np.array([0 if x[0] >= 0.5 else 1 for x in i])) # probs(확률값)을 label로 변경(0.5 이상이면 1, 0.5 미만이면 0)"
      ],
      "metadata": {
        "id": "xT0gPCPtD8-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = list(chain(*y_pred))\n",
        "labels = list(chain(*labels))"
      ],
      "metadata": {
        "id": "oWIlzzIBESC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.116872Z",
          "start_time": "2022-02-02T06:24:23.113064Z"
        },
        "id": "p9BEe2mflTem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e2db8a-c58a-4500-bb04-9116fd585f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.868\n"
          ]
        }
      ],
      "source": [
        "# 정확도 출력 accuracy_score(y_true, y_pred)\n",
        "\n",
        "accuracy_score_data = accuracy_score(labels, y_pred)\n",
        "print(accuracy_score_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.125650Z",
          "start_time": "2022-02-02T06:24:23.117847Z"
        },
        "id": "oCl6BiPGpCPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e474168-fc35-4ebc-ca67-2d5fccc715d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8679999999999999\n"
          ]
        }
      ],
      "source": [
        "# auc 출력 roc_auc_score(y_ture, y_score)\n",
        "roc_auc_score_data = roc_auc_score(labels, y_pred)\n",
        "print(roc_auc_score_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vUn-6PFP5Q3t"
      ],
      "name": "남준우 - Week2_4_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b07fb6415e84849bf570a11b1b6d3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da2e45428ba84722991b9910f9b597b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_152204bd289443fd88447a0906f57a4e",
              "IPY_MODEL_82a3add6add54f4786036d87e7dd85ef",
              "IPY_MODEL_23d72b3a64bf4972b1ce47e938748cee"
            ]
          }
        },
        "da2e45428ba84722991b9910f9b597b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "152204bd289443fd88447a0906f57a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_20489222b2bc455cbee084d8b89383ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9795f755ed2847a1aa4350663f3eb908"
          }
        },
        "82a3add6add54f4786036d87e7dd85ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d44fe95a1344fea92759846e9f774e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 425,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 425,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc85027c2f4a43df8533daa1f25e73db"
          }
        },
        "23d72b3a64bf4972b1ce47e938748cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b254d435d9594f10a2fd38b9eb4f4683",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 425/425 [00:00&lt;00:00, 8.69kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f252004bf2164a269e4d8afb9b30956f"
          }
        },
        "20489222b2bc455cbee084d8b89383ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9795f755ed2847a1aa4350663f3eb908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d44fe95a1344fea92759846e9f774e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc85027c2f4a43df8533daa1f25e73db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b254d435d9594f10a2fd38b9eb4f4683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f252004bf2164a269e4d8afb9b30956f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cf9d40054c14ebf994a24721051bee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1dd96de151c54e0eae831192e0a65ecb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3570eedc7b5435396b02d7fb84617e9",
              "IPY_MODEL_0df9ee36631049e38c93a3e8833ed0ea",
              "IPY_MODEL_bf86aa679c65463692ffb334ef676dcf"
            ]
          }
        },
        "1dd96de151c54e0eae831192e0a65ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3570eedc7b5435396b02d7fb84617e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c5d47549034464f952085b016bc2dcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6b1d16aa2e4432d89f023c1fed7e9f8"
          }
        },
        "0df9ee36631049e38c93a3e8833ed0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e41c449543f41d0bf9161385dcf4480",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445025130,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445025130,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4938f26223144046b9950d79eea583c8"
          }
        },
        "bf86aa679c65463692ffb334ef676dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce0c00d1199842e6beb1e1c3130c9c01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 424M/424M [00:16&lt;00:00, 17.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a321916f2ef49b1b7ac9f4030c2dc03"
          }
        },
        "7c5d47549034464f952085b016bc2dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6b1d16aa2e4432d89f023c1fed7e9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e41c449543f41d0bf9161385dcf4480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4938f26223144046b9950d79eea583c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce0c00d1199842e6beb1e1c3130c9c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a321916f2ef49b1b7ac9f4030c2dc03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}